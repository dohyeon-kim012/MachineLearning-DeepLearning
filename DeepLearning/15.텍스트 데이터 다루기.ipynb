{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15. 텍스트 데이터 다루기",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBStlbtAslWaCEnWOYjCKO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyeon-kim012/MachineLearning-DeepLearning/blob/main/DeepLearning/15.%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%8B%A4%EB%A3%A8%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u7u1JhmiVKW"
      },
      "source": [
        "# Tokenization ( 토큰화 ) 이론\n",
        "어떤 텍스트에서 어디까지가 문장, 어디까지가 단어인지 나눠주는 과정\n",
        "* 문장 토큰화 ( Sentence Tokenization )\n",
        "* 단어 토큰화 ( Word Tokenization )\n",
        "* 음절 토큰화 ( Subword Tokenization )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6K4lAV8i6gM"
      },
      "source": [
        "## English Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75g4gN2Si9vN"
      },
      "source": [
        "sample_text=\"I never thought through love we'd be. Making one as lovely as she. But isn't she lovely made from love.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N364VYazjATf"
      },
      "source": [
        "### 문장 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MhDcoDwjHzu",
        "outputId": "eaaa785f-cbd4-4bd3-ad21-9449221179c8"
      },
      "source": [
        "# 단순하게 온점을 이용해서 잘라내기\n",
        "tokenized_sentence = sample_text.split(\". \")\n",
        "tokenized_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I never thought through love we'd be\",\n",
              " 'Making one as lovely as she',\n",
              " \"But isn't she lovely made from love.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLjCBmC7jVSB"
      },
      "source": [
        "### 단어 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2BBfj9FjbMi",
        "outputId": "8c0d068d-7997-45fe-9322-a1bea8fa0f85"
      },
      "source": [
        "tokenized_word = sample_text.split()  # split() <= split(' ')\n",
        "tokenized_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'never',\n",
              " 'thought',\n",
              " 'through',\n",
              " 'love',\n",
              " \"we'd\",\n",
              " 'be.',\n",
              " 'Making',\n",
              " 'one',\n",
              " 'as',\n",
              " 'lovely',\n",
              " 'as',\n",
              " 'she.',\n",
              " 'But',\n",
              " \"isn't\",\n",
              " 'she',\n",
              " 'lovely',\n",
              " 'made',\n",
              " 'from',\n",
              " 'love.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5fGa9DFjfG5"
      },
      "source": [
        "### 띄어쓰기(공백)로만 영어 문장 내 단어를 구분할 때의 문제점\n",
        "\n",
        "* We're Avengers!! : `[We're, Avengers!!]`\n",
        "* We are Avengers!! : `[We, are, Avengers!!]`\n",
        "* We are Avengers : `[We, are, Avengers]`\n",
        "\n",
        "단순하게 공백으로만 토큰화를 수행하면,   \n",
        "사람은 같은 문장이라는 것을 인지할 수 있으나 기계는 위 세 문장이 다른 문장이라고 판단"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA3iN7dMnVGc"
      },
      "source": [
        "그럼 특수문자를 제거하면?\n",
        "* `[We, re, Avengers]`\n",
        "* `[We, are, Avengers]`\n",
        "* `[We, are, AVengers]`\n",
        "\n",
        "특수문자가 중요한 의미를 가지는 경우에도 특수문자를 제거하면?\n",
        "* $12.45 : `[12, 45]`\n",
        "* Mr. So : `[Mr, So]`\n",
        "* Mrs. Kim : `[Mrs, Kim]`\n",
        "* 192.168.0.1 : `[192, 168, 0, 1]`\n",
        "* Ph.D : `[Ph, D]`\n",
        "\n",
        "---> 특수문자가 중요한 역할을 하는 경우에는 별로 효용적이지 못한 것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7VlS9VxxJZt"
      },
      "source": [
        "## **Word Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn9LqInVnbgZ"
      },
      "source": [
        "#### 미리 준비된 영어단어 토크나이져 준비 하기\n",
        "* TreebankWordTokenizer 패키지\n",
        " * 영어 표준 토큰화 규격을 따라간다.\n",
        " * Penn Treebank Tokenization 규칙\n",
        "\n",
        "* TreebankWordTokenizer 규칙\n",
        " * 하이푼으로 구성된 단어는 하나의 단어로 유지\n",
        " * doesn't 같이 어포스트로피로 '접어'가 함께하는 단어는 따로 분리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3RPeTeejj2P"
      },
      "source": [
        "### English Tockenization 실습\n",
        "\n",
        "설치 코드  \n",
        "```\n",
        "Colab / Jupyter notebook\n",
        "!pip install nltk\n",
        "\n",
        "일반 로컬 터미널\n",
        "pip install nltk\n",
        "```\n",
        "\n",
        "! JVM ( Java Virtual Machine ) 이 설치 되어 있어야 함 !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiiiEaXAoCW5",
        "outputId": "a473637a-d9c3-47c0-990c-df6311397ee6"
      },
      "source": [
        "# 영어에 관련된 패키지는 nltk 패키지에 많이 준비 되어 있음!\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt') # 영어 토크나이져 패키지 다운로드"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faTh49VcozyK"
      },
      "source": [
        "sentence = \"Ain't nothin' sweeter, you want this sugar, don't ya?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPIvaUEmo8zd"
      },
      "source": [
        "#### [English] 기본 토크나이저"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVzgEEyApUJ1",
        "outputId": "9af97bc2-cc60-427c-f834-451d29e84165"
      },
      "source": [
        "print(sentence.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Ain't\", \"nothin'\", 'sweeter,', 'you', 'want', 'this', 'sugar,', \"don't\", 'ya?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysbksS6VpVoU",
        "outputId": "3515f43f-912f-4f36-cfda-84b28e0c200e"
      },
      "source": [
        "# nltk의 기본 Tokenizer 사용\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X79z7gfPqlET"
      },
      "source": [
        "#### [English] WordPunctTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTw9dqKxqqpF",
        "outputId": "b7a7a6ca-e508-4a94-f94a-9ea159c43c34"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "print(tokenizer.tokenize(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ain', \"'\", 't', 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'don', \"'\", 't', 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUSfr7nMqy5a"
      },
      "source": [
        "#### [English] TreebankWordTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgDfdzd2rjz1",
        "outputId": "99140798-9856-4303-b10b-63749da65132"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "print(tokenizer.tokenize(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7zuQMKHrq2y",
        "outputId": "1463b485-686f-4ee3-b65d-ccc84e86fd1c"
      },
      "source": [
        "print(tokenizer.tokenize(\"I'm Iron-Man\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', \"'m\", 'Iron-Man']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqSxODetr8vs"
      },
      "source": [
        "### Korean Tokenization 실습\n",
        "\n",
        "설치 코드\n",
        "```\n",
        "Colab 및 Jupyter notebook에서 설치\n",
        "!pip install konlpy\n",
        "\n",
        "일반 로컬 터미널에서 설치\n",
        "pip install konlpy\n",
        "```\n",
        "\n",
        "! JVM( Java Virtual Machine )이 설치 되어 있어야 한다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F12u-MD-sWVL",
        "outputId": "5cfd590b-be6a-4616-a2a0-424b37b40869"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4b6PI1AsydZ"
      },
      "source": [
        "#### Twitter(Okt), 꼬꼬마(Kkma), 코모란(Komoran), 한나눔(Hannanum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMwBGPdltRIA"
      },
      "source": [
        "from konlpy.tag import Hannanum, Kkma, Komoran, Okt\n",
        "\n",
        "hannanum = Hannanum()\n",
        "kkma = Kkma()\n",
        "komoran = Komoran()\n",
        "okt = Okt()\n",
        "\n",
        "sentence = \"좋으니 그 사람 솔직히 견디기 버거워\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL7hTCSntruO"
      },
      "source": [
        "# konlpy의 모든 형태소 분리기는 duck typing 기법을 활용하여\n",
        "# 명사 추출, 각 형태소별 토큰화, 형태소 토큰 및 종류를 \"튜플\"로 표시하는 기능이 통일\n",
        "def print_tokenizer(tokenizer, s): # (토크나이저 객체, 센텐스)\n",
        "    print(tokenizer.nouns(s))  # 명사만 추출\n",
        "    print(tokenizer.morphs(s))  # 각 형태소 별로 토큰화\n",
        "    print(tokenizer.pos(s))  # 각 형태소 토큰 및 형태소 종류를 튜플로 표현"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkU4eVCfutHd"
      },
      "source": [
        "트위터 ( Okt )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5xNBxWLuxUM",
        "outputId": "04b9e076-7d8d-4052-b31a-4663ca08965f"
      },
      "source": [
        "print_tokenizer(okt, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['그', '사람']\n",
            "['좋으니', '그', '사람', '솔직히', '견디기', '버거워']\n",
            "[('좋으니', 'Adjective'), ('그', 'Noun'), ('사람', 'Noun'), ('솔직히', 'Adjective'), ('견디기', 'Verb'), ('버거워', 'Adjective')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI0X_Bmcuzh-"
      },
      "source": [
        "꼬꼬마 ( Kkma )\n",
        "\n",
        "--> 트위터보다 더 세세하게 분리됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA4jCpxKvEEj",
        "outputId": "0546ba71-3dfa-45e0-c4c8-b0a8fe02eebd"
      },
      "source": [
        "print_tokenizer(kkma, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버겁', '어']\n",
            "[('좋', 'VA'), ('으니', 'ECD'), ('그', 'MDT'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버겁', 'VA'), ('어', 'ECS')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqw5ib27vbvb"
      },
      "source": [
        "[꼬꼬마 품사 태그표](http://kkma.snu.ac.kr/documents/?doc=postag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O06ZxwkvGSJ"
      },
      "source": [
        "코모란 ( Komoran )\n",
        "\n",
        "--> 오탈자에 강건함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX2ct-kYvx9e",
        "outputId": "3c697580-ef50-4826-b462-d91cc5b89fe4"
      },
      "source": [
        "print_tokenizer(komoran, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
            "[('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'NA')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3KSxfYSv5rM"
      },
      "source": [
        "한나눔 ( Hannanum ) \n",
        " \n",
        "--> 잘 안 쓰임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijKRtnLUwNKC",
        "outputId": "29a29ffd-c075-4bd3-bcfb-caac253532d9"
      },
      "source": [
        "print_tokenizer(hannanum, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람', '버거워']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
            "[('좋', 'P'), ('으니', 'E'), ('그', 'M'), ('사람', 'N'), ('솔직히', 'M'), ('견디', 'P'), ('기', 'E'), ('버거워', 'N')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mGiAnU3wQ1l"
      },
      "source": [
        "## **Sentence Tokenization** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c-pOzYGxYFt"
      },
      "source": [
        "#### [English] sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A07YrCx1xbN4"
      },
      "source": [
        "text = \"Since I'm actively looking for Ph.D. students. I get the same question a dozen times every year.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77bpQf3GxemV",
        "outputId": "6fe01508-01d8-48c4-9b60-00de095ee28e"
      },
      "source": [
        "# 온점을 이용해서 문장 나눌 때\n",
        "print(text.split(\".\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Since I'm actively looking for Ph\", 'D', ' students', ' I get the same question a dozen times every year', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp7spa_qxixI",
        "outputId": "406869a7-6176-4d47-be7e-e23af6819e9b"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Since I'm actively looking for Ph.D. students.\", 'I get the same question a dozen times every year.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bBl5VtYxnrI",
        "outputId": "76454e2c-7102-4370-c36d-d5b5145b9834"
      },
      "source": [
        "text = \"My IP Address is 192.168.56.51. Hello World!\"\n",
        "print(text.split(\".\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['My IP Address is 192', '168', '56', '51', ' Hello World!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NFyMFOPxvcM",
        "outputId": "a011fb88-a60a-4d00-d830-afa25b1f3fb0"
      },
      "source": [
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['My IP Address is 192.168.56.51.', 'Hello World!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz87PXtQxxFd"
      },
      "source": [
        "#### [Korean] kss\n",
        "\n",
        "설치 방법\n",
        "```\n",
        "!pip install kss\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DkeHy6mCrxV",
        "outputId": "358139d8-3470-4e93-cd67-878b6b302b2e"
      },
      "source": [
        "!pip install kss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kss in /usr/local/lib/python3.7/dist-packages (2.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sGOzWvsCtjO",
        "outputId": "57389ac2-b9aa-423f-d316-54124f2b2bd8"
      },
      "source": [
        "import kss\n",
        "text = \"제 아이피는 192.168.56.51 이에요. 자연어 처리가 재미있나요?ㅋㅋ\"\n",
        "\n",
        "print(kss.split_sentences(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['제 아이피는 192.168.56.51 이에요.', '자연어 처리가 재미있나요?ㅋㅋ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jdqj9_qOC-VA"
      },
      "source": [
        "### [Korean] 띄어쓰기 및 맞춤법 정리\n",
        "\n",
        "### KoSpacing\n",
        "```\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "```\n",
        "### Hanspell\n",
        "```\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zPCmeTgDWaN"
      },
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHNyQ_yBDYLS"
      },
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mshhu93DZaA"
      },
      "source": [
        "from pykospacing import Spacing # 한국어 띄어쓰기 관리 패키지\n",
        "from hanspell import spell_checker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS8CYQTWDvy_"
      },
      "source": [
        "spacing = Spacing()  # 띄어쓰기 관리 객체"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvIHTTUjEaTF"
      },
      "source": [
        "text = \"4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aIkK2ZQEg3L",
        "outputId": "03ac61a7-1a33-44f5-a7f9-7845d2107bd2"
      },
      "source": [
        "spacing_text = spacing(text)\n",
        "print(spacing_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "딥러닝 진짜 어렵 닼ㅋㅋ 이렇게 어려울지 몰랐어 옄ㅋㅋ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW-Pti9GEj0C",
        "outputId": "49f2b5a1-b93d-4aab-cfb0-7246bf4cea3d"
      },
      "source": [
        "hanspell_text = spell_checker.check(text)\n",
        "print(hanspell_text.checked)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "딥러닝 진짜 어렵다ᄏᄏ 이렇게 어려울지 몰랐어옄ㅋㅋ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi_eWyigErKW",
        "outputId": "b198a976-814d-49d4-e4a9-5e81492a29da"
      },
      "source": [
        "|# 맞춤법 검사\n",
        "text = \"맞춤뻡 틀리면 외 않되?\"\n",
        "hanspell_text = spell_checker.check(text).checked\n",
        "print(hanspell_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "맞춤법 틀리면 왜 안돼?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaUYyMiiE5Fu"
      },
      "source": [
        "# 텍스트 정규화 ( normalization )\n",
        "\n",
        "문장의 복잡도를 낮춰주는 과정  \n",
        "\n",
        "복잡도가 낮아지기 때문에 **처리할 텍스트 줄어든다**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VpGuMeGEC0"
      },
      "source": [
        "## [English] Stemming\n",
        "\n",
        "**어간 ( stem ) 을 추출**하는 과정  \n",
        "- 영어는 사전에 없는 이상한 단어가 나오는 경우도 있음\n",
        "    - Beautiful 의 어간 : `beaut`  ->  beaut(iful), beaut(y)\n",
        "    - Allowance : `allow`\n",
        "    - Medical : `medic`\n",
        "    - Books : `book`\n",
        "    - This : `thi`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2jETxG8HB2K"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "porter_stemmer = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8UU02wcHaHE"
      },
      "source": [
        "text = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6T4j-JtHlcd",
        "outputId": "528b8175-2af6-4578-8606-f76d10207660"
      },
      "source": [
        "words = word_tokenize(text)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQWidpg9H5wQ",
        "outputId": "5c79055f-a215-4d37-c091-079f01d4f192"
      },
      "source": [
        "stem_list = [porter_stemmer.stem(w) for w in words] # 리스트 컴프리헨션\n",
        "print(stem_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaUWkq5aH_Ts"
      },
      "source": [
        "언어의 단어 모양이 변경되는 형식은 **자연어 생성 모델**을 만들 때는 사용하면 안 됨  \n",
        "\n",
        "but , 단순 분류나 회귀문제를 풀 때는 효과가 있을 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYGYz6nVIpU5",
        "outputId": "62f5edaf-af4c-44fa-970b-44baf92b85d5"
      },
      "source": [
        "words = [\"Serialize\", \"Allowance\", \"Allowed\", \"Medical\", \"This\", \"Pretty\", \"Beautiful\"]\n",
        "print([porter_stemmer.stem(w) for w in words])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['serial', 'allow', 'allow', 'medic', 'thi', 'pretti', 'beauti']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6q-jIkTJWhR"
      },
      "source": [
        "## [Korean] Okt 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f34epHsZJqmy",
        "outputId": "11f03ea5-9ee3-4185-8703-733137d5e3d6"
      },
      "source": [
        "# Stemming\n",
        "okt = Okt()\n",
        "text = \"이것도 모르고 저것도 모르고 아무것도 모르면 뭘 모르는지도 모르더라.\"\n",
        "\n",
        "print(okt.morphs(text))\n",
        "print(okt.morphs(text, stem=True))  # 어간이 추출된 형태소 분리 일어남"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이', '것', '도', '모르고', '저', '것', '도', '모르고', '아무', '것', '도', '모르면', '뭘', '모르는지도', '모르더라', '.']\n",
            "['이', '것', '도', '모르다', '저', '것', '도', '모르다', '아무', '것', '도', '모르다', '뭘', '모르다', '모르다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIx2R_v_J6Rx",
        "outputId": "81867945-5de7-498d-dcf0-87292cf96f6c"
      },
      "source": [
        "print(okt.pos(text))\n",
        "print(okt.pos(text, stem=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르고', 'Verb'), ('저', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르고', 'Verb'), ('아무', 'Modifier'), ('것', 'Noun'), ('도', 'Josa'), ('모르면', 'Verb'), ('뭘', 'Noun'), ('모르는지도', 'Verb'), ('모르더라', 'Verb'), ('.', 'Punctuation')]\n",
            "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르다', 'Verb'), ('저', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르다', 'Verb'), ('아무', 'Modifier'), ('것', 'Noun'), ('도', 'Josa'), ('모르다', 'Verb'), ('뭘', 'Noun'), ('모르다', 'Verb'), ('모르다', 'Verb'), ('.', 'Punctuation')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeC0GSZQKNNM",
        "outputId": "151d2fcb-3289-4090-9243-8a66f1c90fdd"
      },
      "source": [
        "# Normalization\n",
        "text = \"딥러닝 진짜 어렵닼ㅋㅋ 이렇게 어려울지 몰랐어옄ㅋㅋ\"\n",
        "print(okt.pos(text))\n",
        "print(okt.pos(text, norm=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('딥', 'Noun'), ('러닝', 'Noun'), ('진짜', 'Noun'), ('어렵닼', 'Noun'), ('ㅋㅋ', 'KoreanParticle'), ('이렇게', 'Adverb'), ('어려울지', 'Verb'), ('몰랐어', 'Verb'), ('옄', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n",
            "[('딥', 'Noun'), ('러닝', 'Noun'), ('진짜', 'Noun'), ('어렵다', 'Adjective'), ('ㅋㅋ', 'KoreanParticle'), ('이렇게', 'Adverb'), ('어려울지', 'Verb'), ('몰랐어여', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0-vaVY1Kfwr",
        "outputId": "18df31aa-fe51-4eaf-cc73-a256332da6d2"
      },
      "source": [
        "# 어간 추출, 정규화 동시에\n",
        "print(okt.pos(text, stem=True, norm=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('딥', 'Noun'), ('러닝', 'Noun'), ('진짜', 'Noun'), ('어렵다', 'Adjective'), ('ㅋㅋ', 'KoreanParticle'), ('이렇게', 'Adverb'), ('어리다', 'Verb'), ('모르다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJkXJh49LFWV"
      },
      "source": [
        "## [Korean] 이모티콘 / 의미 없이 반복되는 문자 정제\n",
        "\n",
        "- ㅋㅋ, ㅋㅋㅋㅋㅋㅋ\n",
        "- ㅎㅎㅎㅎ\n",
        "\n",
        "- 잘한다 ㅠㅠㅠ : 긍정의 표현으로 많이 사용\n",
        "- 잘한다 ㅋㅋㅋ : 긍정 또는 약간의 부정(비웃음)으로도 사용될 수 있음\n",
        "```\n",
        "!pip install soynlp\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCYREE9iLlLk",
        "outputId": "844eef98-dfe4-4657-e4c9-6dc12d839fa1"
      },
      "source": [
        "!pip install soynlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soynlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
            "\r\u001b[K     |▉                               | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 20.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40kB 16.4MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 419kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.0.1)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K96X6Q76LnDV",
        "outputId": "fbf7fbaf-c784-40e6-adfa-01649f7980e5"
      },
      "source": [
        "from soynlp.normalizer import emoticon_normalize\n",
        "\n",
        "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋ 딥러닝 재미쓰ㅠㅠㅠㅠㅠㅠ\", num_repeats=2))\n",
        "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋㅋㅋ 딥러닝 재미쓰ㅠㅠㅠㅠㅠㅠ\", num_repeats=2))\n",
        "a = emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 딥러닝 재미쓰ㅠㅠㅠㅠㅠㅠ\", num_repeats=3)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "아ㅋㅋ 딥러닝 재미쓰ㅠㅠ\n",
            "아ㅋㅋ 딥러닝 재미쓰ㅠㅠ\n",
            "아ㅋㅋㅋ 딥러닝 재미쓰ㅠㅠㅠ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAPrZ9PhMEao",
        "outputId": "1aa11d28-313b-4db2-fc6c-77d8ef805d93"
      },
      "source": [
        "# 반복되는 문자를 정규화\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "\n",
        "print(repeat_normalize(\"문을 쿵쿵쿵쿵쿵쿵 두드렸다\", num_repeats=2))\n",
        "print(repeat_normalize(\"문을 쿵쿵쿵쿵쿵쿵 두드렸다\", num_repeats=3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문을 쿵쿵 두드렸다\n",
            "문을 쿵쿵쿵 두드렸다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-fm36JLMTiv"
      },
      "source": [
        "# 텍스트 정제 ( Cleaning )\n",
        "\n",
        "1. 정규식을 이용한 정제\n",
        "    - 특수기호나 의미 없는 공백 등을 정규식을 활용하여 제거\n",
        "\n",
        "2. 불용어 ( stopwords ) 정제\n",
        "    - 불용어 : 분석에 큰 의미가 없는 단어\n",
        "    - 빈도수가 낮거나, 짧거나, 의미가 없는 단어를 문장에서 제거\n",
        "        - ex) the, a, an, is, I 등 문장을 구성하는 필수 요소이나 문맥적으로는 큰 의미가 없는 단어"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMPHV8VESSZ_"
      },
      "source": [
        "## [English] 정규 표현식 정제\n",
        "\n",
        "영어만 추출하는 정규식 표현 : `[a-zA-Z]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WrrlUqbNRWc",
        "outputId": "34bd8064-34aa-4902-acce-bb36aa50be01"
      },
      "source": [
        "import re\n",
        "\n",
        "eng_sent = \"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\"\n",
        "print(eng_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Yeah, do you expect people to read the FAQ, etc. and actually accept hard\n",
            "atheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\n",
            "of steam!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jim,\n",
            "\n",
            "Sorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\n",
            "denial about the faith you need to get by.  Oh well, just pretend that it will\n",
            "all end happily ever after anyway.  Maybe if you start a new newsgroup,\n",
            "alt.atheist.hard, you won't be bummin' so much?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \n",
            "--\n",
            "Bake Timmons, III\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWybiUhUQqja",
        "outputId": "5b671306-047a-4b03-c9dd-a68733cdb12b"
      },
      "source": [
        "# 위 문장에서 영어가 아닌 것들을 전부 다 공백으로 치환\n",
        "#   sub : replace와 같은 역할\n",
        "eng_sent = re.sub(\"[^a-zA-Z]\", \" \", eng_sent)\n",
        "# [] : 대괄호 안쪽의 '한 글자' 의미\n",
        "# [^] 대괄호 안쪽의 글자가 '아닌 것'\n",
        "#  --> [^a-zA-Z] a-z, A-Z가 아닌 글자\n",
        "\n",
        "print(eng_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Yeah  do you expect people to read the FAQ  etc  and actually accept hard atheism   No  you need a little leap of faith  Jimmy   Your logic runs out of steam         Jim   Sorry I can t pity you  Jim   And I m sorry that you have these feelings of denial about the faith you need to get by   Oh well  just pretend that it will all end happily ever after anyway   Maybe if you start a new newsgroup  alt atheist hard  you won t be bummin  so much        Bye Bye  Big Jim   Don t forget your Flintstone s Chewables          Bake Timmons  III\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcazcX26RioY",
        "outputId": "c4ace083-ddef-48e1-e18e-9e7347125a2b"
      },
      "source": [
        "# 4글자 이상인 단어만 추출하여 문장 재구성\n",
        "eng_sent = \" \".join([w for w in eng_sent.split() if len(w) > 3])\n",
        "print(eng_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yeah expect people read actually accept hard atheism need little leap faith Jimmy Your logic runs steam Sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway Maybe start newsgroup atheist hard bummin much forget your Flintstone Chewables Bake Timmons\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K51tPxjICOlF",
        "outputId": "d3b8be05-ec0f-4e6f-dfa0-8928058a5edf"
      },
      "source": [
        "_iter = iter([1,2,3,4,5])\n",
        "_iter\n",
        "_list = list([1,2,3,4,5])\n",
        "_list\n",
        "len(list(_iter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SOiw-h2ChhE",
        "outputId": "496d3693-735a-42a4-c5a5-cd3d326ed543"
      },
      "source": [
        "for i in _list:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY680npHCr8b",
        "outputId": "56eff774-d9b2-4f0b-82ff-bc4b32f4c53b"
      },
      "source": [
        "_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKm4MdflR5FO"
      },
      "source": [
        "## [Korean] 정규 표현식 정제\n",
        "\n",
        "한글만 추출하는 정규식 표현 : `[ㄱ-ㅎㅏ-ㅣ가-힣]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1RiU9MgSgFp"
      },
      "source": [
        "kor_sent = \"느그 서장 남천동 살제? 내가 임마 느그 서장이랑 으이?? in Busan\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xkVL-DZeSyy6",
        "outputId": "95abce05-61f9-4afe-a6d3-7cfcdbc2f7a6"
      },
      "source": [
        "# 한글이 아닌 것 제거 -> [^]\n",
        "kor_sent = re.sub(\"[^ㄱ-하-ㅣ가-힣]\", \" \", kor_sent)\n",
        "kor_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'느그 서장 남천동 살제  내가 임마 느그 서장이랑 으이           '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhuVWjU0TAUW"
      },
      "source": [
        "공백이 2개 이상이면 사라지게 하기  \n",
        "--> 2개 이상의 공백을 1개로 치환하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IOWbz5fuTc8V",
        "outputId": "e8ff373b-bbb2-4ee2-c092-e9a8b039c6ff"
      },
      "source": [
        "kor_sent = re.sub(\"[ ]{2,}\", \" \", kor_sent) # [ ] : 공백 '한 글자' , {} : 반복 정규식\n",
        "# re.sub(2개 이상의 공백을, 한 개의 공백으로 묶어주겠다, kor_sent에서)\n",
        "kor_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'느그 서장 남천동 살제 내가 임마 느그 서장이랑 으이 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e5IgOgiBT2JE",
        "outputId": "0195996b-b826-4e21-8c6e-125a6bcb687f"
      },
      "source": [
        "kor_sent.strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'느그 서장 남천동 살제 내가 임마 느그 서장이랑 으이'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtU_PMmTT30m"
      },
      "source": [
        "## [English] 불용어 정제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtcC1_n5UToe",
        "outputId": "2bd679a1-db18-44ac-9113-613ba1485892"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")  # 불용어 사전 다운로드"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8xZ5mD_UYKG",
        "outputId": "0a880352-15ce-4516-b045-a8520dd37cd8"
      },
      "source": [
        "# 불용어를 비즈니스에 맞게 설정할 수 있어야 함\n",
        "from nltk.corpus import stopwords\n",
        "list(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM2FslZZUq1a",
        "outputId": "d437e306-2ea8-486c-8a27-7c1136b9f4a6"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "list(stopwords.words('german'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aber',\n",
              " 'alle',\n",
              " 'allem',\n",
              " 'allen',\n",
              " 'aller',\n",
              " 'alles',\n",
              " 'als',\n",
              " 'also',\n",
              " 'am',\n",
              " 'an',\n",
              " 'ander',\n",
              " 'andere',\n",
              " 'anderem',\n",
              " 'anderen',\n",
              " 'anderer',\n",
              " 'anderes',\n",
              " 'anderm',\n",
              " 'andern',\n",
              " 'anderr',\n",
              " 'anders',\n",
              " 'auch',\n",
              " 'auf',\n",
              " 'aus',\n",
              " 'bei',\n",
              " 'bin',\n",
              " 'bis',\n",
              " 'bist',\n",
              " 'da',\n",
              " 'damit',\n",
              " 'dann',\n",
              " 'der',\n",
              " 'den',\n",
              " 'des',\n",
              " 'dem',\n",
              " 'die',\n",
              " 'das',\n",
              " 'dass',\n",
              " 'daß',\n",
              " 'derselbe',\n",
              " 'derselben',\n",
              " 'denselben',\n",
              " 'desselben',\n",
              " 'demselben',\n",
              " 'dieselbe',\n",
              " 'dieselben',\n",
              " 'dasselbe',\n",
              " 'dazu',\n",
              " 'dein',\n",
              " 'deine',\n",
              " 'deinem',\n",
              " 'deinen',\n",
              " 'deiner',\n",
              " 'deines',\n",
              " 'denn',\n",
              " 'derer',\n",
              " 'dessen',\n",
              " 'dich',\n",
              " 'dir',\n",
              " 'du',\n",
              " 'dies',\n",
              " 'diese',\n",
              " 'diesem',\n",
              " 'diesen',\n",
              " 'dieser',\n",
              " 'dieses',\n",
              " 'doch',\n",
              " 'dort',\n",
              " 'durch',\n",
              " 'ein',\n",
              " 'eine',\n",
              " 'einem',\n",
              " 'einen',\n",
              " 'einer',\n",
              " 'eines',\n",
              " 'einig',\n",
              " 'einige',\n",
              " 'einigem',\n",
              " 'einigen',\n",
              " 'einiger',\n",
              " 'einiges',\n",
              " 'einmal',\n",
              " 'er',\n",
              " 'ihn',\n",
              " 'ihm',\n",
              " 'es',\n",
              " 'etwas',\n",
              " 'euer',\n",
              " 'eure',\n",
              " 'eurem',\n",
              " 'euren',\n",
              " 'eurer',\n",
              " 'eures',\n",
              " 'für',\n",
              " 'gegen',\n",
              " 'gewesen',\n",
              " 'hab',\n",
              " 'habe',\n",
              " 'haben',\n",
              " 'hat',\n",
              " 'hatte',\n",
              " 'hatten',\n",
              " 'hier',\n",
              " 'hin',\n",
              " 'hinter',\n",
              " 'ich',\n",
              " 'mich',\n",
              " 'mir',\n",
              " 'ihr',\n",
              " 'ihre',\n",
              " 'ihrem',\n",
              " 'ihren',\n",
              " 'ihrer',\n",
              " 'ihres',\n",
              " 'euch',\n",
              " 'im',\n",
              " 'in',\n",
              " 'indem',\n",
              " 'ins',\n",
              " 'ist',\n",
              " 'jede',\n",
              " 'jedem',\n",
              " 'jeden',\n",
              " 'jeder',\n",
              " 'jedes',\n",
              " 'jene',\n",
              " 'jenem',\n",
              " 'jenen',\n",
              " 'jener',\n",
              " 'jenes',\n",
              " 'jetzt',\n",
              " 'kann',\n",
              " 'kein',\n",
              " 'keine',\n",
              " 'keinem',\n",
              " 'keinen',\n",
              " 'keiner',\n",
              " 'keines',\n",
              " 'können',\n",
              " 'könnte',\n",
              " 'machen',\n",
              " 'man',\n",
              " 'manche',\n",
              " 'manchem',\n",
              " 'manchen',\n",
              " 'mancher',\n",
              " 'manches',\n",
              " 'mein',\n",
              " 'meine',\n",
              " 'meinem',\n",
              " 'meinen',\n",
              " 'meiner',\n",
              " 'meines',\n",
              " 'mit',\n",
              " 'muss',\n",
              " 'musste',\n",
              " 'nach',\n",
              " 'nicht',\n",
              " 'nichts',\n",
              " 'noch',\n",
              " 'nun',\n",
              " 'nur',\n",
              " 'ob',\n",
              " 'oder',\n",
              " 'ohne',\n",
              " 'sehr',\n",
              " 'sein',\n",
              " 'seine',\n",
              " 'seinem',\n",
              " 'seinen',\n",
              " 'seiner',\n",
              " 'seines',\n",
              " 'selbst',\n",
              " 'sich',\n",
              " 'sie',\n",
              " 'ihnen',\n",
              " 'sind',\n",
              " 'so',\n",
              " 'solche',\n",
              " 'solchem',\n",
              " 'solchen',\n",
              " 'solcher',\n",
              " 'solches',\n",
              " 'soll',\n",
              " 'sollte',\n",
              " 'sondern',\n",
              " 'sonst',\n",
              " 'über',\n",
              " 'um',\n",
              " 'und',\n",
              " 'uns',\n",
              " 'unsere',\n",
              " 'unserem',\n",
              " 'unseren',\n",
              " 'unser',\n",
              " 'unseres',\n",
              " 'unter',\n",
              " 'viel',\n",
              " 'vom',\n",
              " 'von',\n",
              " 'vor',\n",
              " 'während',\n",
              " 'war',\n",
              " 'waren',\n",
              " 'warst',\n",
              " 'was',\n",
              " 'weg',\n",
              " 'weil',\n",
              " 'weiter',\n",
              " 'welche',\n",
              " 'welchem',\n",
              " 'welchen',\n",
              " 'welcher',\n",
              " 'welches',\n",
              " 'wenn',\n",
              " 'werde',\n",
              " 'werden',\n",
              " 'wie',\n",
              " 'wieder',\n",
              " 'will',\n",
              " 'wir',\n",
              " 'wird',\n",
              " 'wirst',\n",
              " 'wo',\n",
              " 'wollen',\n",
              " 'wollte',\n",
              " 'würde',\n",
              " 'würden',\n",
              " 'zu',\n",
              " 'zum',\n",
              " 'zur',\n",
              " 'zwar',\n",
              " 'zwischen']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkVdrt0tUuo9",
        "outputId": "4e9a8fa6-ebfe-446c-9c4c-f53a062cd445"
      },
      "source": [
        "example = \"Family is not an important thing. It's everything\"\n",
        "\n",
        "# 불용어 사전 중에서 중복된 내용 제거\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "word_tokens = word_tokenize(example.lower())  # 문장 전체를 소문자로 만든 다음 토큰화\n",
        "\n",
        "# 불용어 사전에 들어있지 않은 단어면 리스트에 추가\n",
        "result = [w for w in word_tokens if w not in stop_words]\n",
        "\n",
        "print(\"원본 : {}\".format(word_tokens))\n",
        "print(\"불용어 제거 후 : {}\".format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 : ['family', 'is', 'not', 'an', 'important', 'thing', '.', 'it', \"'s\", 'everything']\n",
            "불용어 제거 후 : ['family', 'important', 'thing', '.', \"'s\", 'everything']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gUWt8iMVptM"
      },
      "source": [
        "## [Korean] 불용어 정제\n",
        "\n",
        "한국어 불용어 사전은 직접 만들거나 구글링해서 가져와야 한다  \n",
        "\n",
        "--> 개발자가 직접 정의하는 것이 일반적임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdJASou6WBqu",
        "outputId": "5bfa7856-2c82-4db7-aa4e-74ac5d3422a4"
      },
      "source": [
        "example = \"내 패와 정마담 패를 밑에서 뺐지. 내가 빙다리 핫바지로 보이냐\"\n",
        "word_tokens = okt.morphs(example)\n",
        "\n",
        "print(word_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['내', '패', '와', '정마담', '패', '를', '밑', '에서', '뺐지', '.', '내', '가', '빙', '다리', '핫바', '지로', '보이냐']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBQiianBWS0-"
      },
      "source": [
        "개발자가 임의로 불용어를 선정할 수 있다  \n",
        "일반적으로 조사, 접속사들이 불용어로 선정됨  \n",
        "그러나 위와 같이 추출된 상태에서는 조사를 잘 구분해낼 수 없음  \n",
        "따라서, 불용어 정제 전 맞춤법을 한 번 체크해보는 것도 좋다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCIWAmh4W8o3",
        "outputId": "a868e124-ed65-4a27-cbd0-dcd0ddffff1e"
      },
      "source": [
        "example_spell_check = spell_checker.check(example).checked\n",
        "word_tokens = okt.morphs(example_spell_check)\n",
        "print(word_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['내', '패', '와', '정마담', '패', '를', '밑', '에서', '뺐지', '.', '내', '가', '비', '에', '다리', '핫바', '지로', '보이냐']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELRqRkzgXByA"
      },
      "source": [
        "stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '것', '게']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuurHK15XLH1",
        "outputId": "b5aa0923-7200-4afc-ec01-597482d3151a"
      },
      "source": [
        "result = [w for w in word_tokens if not w in stop_words]\n",
        "\n",
        "print(\"원문 : \", word_tokens)\n",
        "print(\"불용어 제거 후 : {}\".format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  ['내', '패', '와', '정마담', '패', '를', '밑', '에서', '뺐지', '.', '내', '가', '비', '에', '다리', '핫바', '지로', '보이냐']\n",
            "불용어 제거 후 : ['내', '패', '정마담', '패', '밑', '에서', '뺐지', '.', '내', '비', '다리', '핫바', '지로', '보이냐']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Walw5IidjOi-",
        "outputId": "2ff7c2de-a827-4f3f-9611-7d0d04b84e0d"
      },
      "source": [
        "divisor_three = [x for x in range(1,51) if x % 3 == 0 if x > 10]\n",
        "divisor_three"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK2RzkiQjc_c",
        "outputId": "a6567adb-04a2-4775-de7b-7fc0659d81af"
      },
      "source": [
        "rows = range(1, 4)\n",
        "cols = range(2, 4)\n",
        "cells = [(row, col) for row in rows for col in cols if col == 3]\n",
        "for cell in cells:\n",
        "    print(cell)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3)\n",
            "(2, 3)\n",
            "(3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yFusWPHlJJn",
        "outputId": "c9e7b111-37ab-4b3a-9899-1595b0abf1ac"
      },
      "source": [
        "letter_count = {letter : example.count(letter) for letter in set(example)}\n",
        "letter_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 9,\n",
              " '.': 1,\n",
              " '가': 1,\n",
              " '내': 2,\n",
              " '냐': 1,\n",
              " '다': 1,\n",
              " '담': 1,\n",
              " '로': 1,\n",
              " '를': 1,\n",
              " '리': 1,\n",
              " '마': 1,\n",
              " '밑': 1,\n",
              " '바': 1,\n",
              " '보': 1,\n",
              " '빙': 1,\n",
              " '뺐': 1,\n",
              " '서': 1,\n",
              " '에': 1,\n",
              " '와': 1,\n",
              " '이': 1,\n",
              " '정': 1,\n",
              " '지': 2,\n",
              " '패': 2,\n",
              " '핫': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6jYIcYDm_EM",
        "outputId": "646df2e0-d8f4-4114-faee-bcdea913519a"
      },
      "source": [
        "cells.append((3, 3))\n",
        "\n",
        "cells"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3), (2, 3), (3, 3), (3, 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1oBuW7NngFO",
        "outputId": "6b48a2ee-2d08-4a42-a12b-fbdf706a9412"
      },
      "source": [
        "for cell in cells:\n",
        "    print(cell)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3)\n",
            "(2, 3)\n",
            "(3, 3)\n",
            "(3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wub7qiTynnW2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}